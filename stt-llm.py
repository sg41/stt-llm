import speech_recognition as sr
import numpy as np
from transformers import pipeline
import requests
import sys, os

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_MODEL = "meta-llama/llama-3.1-8b-instruct"  # –∏–ª–∏ –¥—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å

DEVICE_INDEX = 0  # –ò–Ω–¥–µ–∫—Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ (—É –≤–∞—Å ‚Äî 0)

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
print("–ó–∞–≥—Ä—É–∑–∫–∞ Whisper...")
transcriber = pipeline(
    "automatic-speech-recognition",
    model="openai/whisper-small",
    device=-1,  # CPU
    return_timestamps=False,
    generate_kwargs={"language": "russian", "task": "transcribe"}
)

r = sr.Recognizer()
r.energy_threshold = 400
r.dynamic_energy_threshold = True

headers = {
    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
    "HTTP-Referer": "https://your-app.local",
    "X-Title": "Voice-to-LLM"
}

def audio_to_numpy(audio_data, target_rate=16000):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç AudioData –≤ numpy –º–∞—Å—Å–∏–≤ –¥–ª—è Whisper"""
    raw = audio_data.get_wav_data(convert_rate=target_rate, convert_width=2)
    audio_np = np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0
    return audio_np

def transcribe_with_whisper(audio_data):
    try:
        audio_np = audio_to_numpy(audio_data)
        result = transcriber(audio_np)
        return result['text'].strip()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Whisper: {e}")
        return ""

def query_openrouter(prompt):
    payload = {
        "model": OPENROUTER_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 500
    }
    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        if response.status_code == 200:
            data = response.json()
            return data["choices"][0]["message"]["content"]
        else:
            print(f"‚ùå OpenRouter –æ—à–∏–±–∫–∞ {response.status_code}: {response.text}")
            return None
    except Exception as e:
        print(f"‚ùå –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞: {e}")
        return None

# === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ===
def main():
    print("\nüéôÔ∏è  –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≥–æ—Ç–æ–≤. –ì–æ–≤–æ—Ä–∏—Ç–µ ‚Äî –∑–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
    print("   –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞.\n")

    first_run = True
    with sr.Microphone(device_index=DEVICE_INDEX) as source:
        while True:
            try:
                print("üëÇ –°–ª—É—à–∞—é...")
                audio = r.listen(source, timeout=10)
                print("‚úÖ –ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–∞—Å–ø–æ–∑–Ω–∞—é...")

                user_text = transcribe_with_whisper(audio)
                if not user_text:
                    print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.\n")
                    continue

                print(f"üí¨ –í—ã —Å–∫–∞–∑–∞–ª–∏: {user_text}")

                if first_run:
                    print("ü§ñ Skip fist run")
                    first_run = False
                    continue

                print("üß† –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ LLM...")
                llm_response = query_openrouter(user_text)
                if llm_response:
                    print(f"ü§ñ –û—Ç–≤–µ—Ç:\n{llm_response}\n")
                else:
                    print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏.\n")

            except sr.WaitTimeoutError:
                print("‚è≥ –¢–∞–π–º–∞—É—Ç: –Ω–∏–∫—Ç–æ –Ω–µ –≥–æ–≤–æ—Ä–∏—Ç.\n")
            except KeyboardInterrupt:
                print("\nüëã –í—ã—Ö–æ–¥.")
                sys.exit(0)
            except Exception as e:
                print(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}\n")

if __name__ == "__main__":
    main()